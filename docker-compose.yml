version: '3.8'

services:
  api-gateway:
    container_name: api-gateway
    build:
      context: .
      dockerfile: Dockerfile
      args:
        SERVICE: api-gateway
    ports:
      - '8080:8080'
    command: node dist/main.js
    depends_on:
      kafka:
        condition: service_healthy
      redis:
        condition: service_started
    env_file: .env
    environment:
      - API_GATEWAY_PORT=${API_GATEWAY_PORT}
    networks:
      - microservice-network

  user-service:
    container_name: user-service
    build:
      context: .
      dockerfile: Dockerfile
      args:
        SERVICE: user-service
    ports:
      - '8081:8081'
      - '50051:50051'
    command: node dist/main.js
    depends_on:
      kafka:
        condition: service_healthy
      postgres:
        condition: service_healthy
      redis:
        condition: service_started
    env_file: .env
    environment:
      - POSTGRES_DB=${USER_SERVICE_DB}
      - USER_SERVICE_PORT=${USER_SERVICE_PORT}
    networks:
      - microservice-network

  product-service:
    container_name: product-service
    build:
      context: .
      dockerfile: Dockerfile
      args:
        SERVICE: product-service
    ports:
      - '8082:8082'
      - '50052:50052'
    command: node dist/main.js
    depends_on:
      kafka:
        condition: service_healthy
      postgres:
        condition: service_healthy
      redis:
        condition: service_started
    env_file: .env
    environment:
      - POSTGRES_DB=${PRODUCT_SERVICE_DB}
      - PRODUCT_SERVICE_PORT=${PRODUCT_SERVICE_PORT}
    networks:
      - microservice-network

  logger-service:
    container_name: logger-service
    build:
      context: .
      dockerfile: Dockerfile
      args:
        SERVICE: logger-service
    ports:
      - '8083:8083'
    command: node dist/main.js
    depends_on:
      kafka:
        condition: service_healthy
      postgres:
        condition: service_healthy
      redis:
        condition: service_started
    env_file: .env
    environment:
      - LOGGER_SERVICE_PORT=${LOGGER_SERVICE_PORT}
    networks:
      - microservice-network

  # Message Broker
  kafka:
    container_name: kafka
    image: confluentinc/cp-kafka:7.3.1
    ports:
      - '9092:9092'
    environment:
      KAFKA_BROKER_ID: ${KAFKA_BROKER_ID}
      KAFKA_ZOOKEEPER_CONNECT: ${KAFKA_ZOOKEEPER_CONNECT}
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: ${KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR}
    depends_on:
      - zookeeper
    healthcheck:
      test: ['CMD', 'nc', '-z', 'localhost', '9092']
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - microservice-network

  zookeeper:
    container_name: zookeeper
    image: confluentinc/cp-zookeeper:latest
    ports:
      - '${ZOOKEEPER_CLIENT_PORT}:${ZOOKEEPER_CLIENT_PORT}'
    environment:
      ZOOKEEPER_CLIENT_PORT: ${ZOOKEEPER_CLIENT_PORT}
    networks:
      - microservice-network

  # Cache
  redis:
    container_name: redis
    image: redis:alpine
    ports:
      - '${REDIS_PORT}:${REDIS_PORT}'
    healthcheck:
      test: ['CMD', 'redis-cli', 'ping']
      interval: 5s
      timeout: 3s
      retries: 5
    networks:
      - microservice-network

  # Database
  postgres:
    container_name: postgres
    image: postgres:15-alpine
    ports:
      - '5432:5432'
    environment:
      DB_HOST: postgres # Use Docker service name
      DB_PORT: 5432
      POSTGRES_USER: ${DB_USERNAME}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_HOST_AUTH_METHOD: trust
    healthcheck:
      test: ['CMD-SHELL', 'pg_isready -U ${DB_USERNAME} -d postgres']
      interval: 10s
      timeout: 5s
      retries: 5
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./config/postgres/init:/docker-entrypoint-initdb.d
    networks:
      - microservice-network

  # ELK Stack
  elasticsearch:
    container_name: elasticsearch
    image: docker.elastic.co/elasticsearch/elasticsearch:7.14.0
    ports:
      - '9200:9200'
      - '9300:9300'
    environment:
      - discovery.type=single-node
      - ES_JAVA_OPTS=${ELASTICSEARCH_JAVA_OPTS}
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    networks:
      - microservice-network

  logstash:
    container_name: logstash
    image: docker.elastic.co/logstash/logstash:7.14.0
    ports:
      - '5000:5000'
      - '9600:9600'
    volumes:
      - ./config/logstash/pipeline:/usr/share/logstash/pipeline
    depends_on:
      - elasticsearch
      - kafka
    networks:
      - microservice-network

  kibana:
    container_name: kibana
    image: docker.elastic.co/kibana/kibana:7.14.0
    ports:
      - '5601:5601'
    environment:
      ELASTICSEARCH_HOSTS: ${KIBANA_ELASTICSEARCH_HOSTS}
    depends_on:
      - elasticsearch
    networks:
      - microservice-network

  # Monitoring
  grafana:
    container_name: grafana
    image: grafana/grafana:latest
    ports:
      - '9999:3000'
    volumes:
      - grafana-data:/var/lib/grafana
      - ./config/grafana/provisioning:/etc/grafana/provisioning
    depends_on:
      - prometheus
    networks:
      - microservice-network

  prometheus:
    container_name: prometheus
    image: prom/prometheus:latest
    ports:
      - '9090:9090'
    volumes:
      - ./config/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    networks:
      - microservice-network

networks:
  microservice-network:
    driver: bridge

volumes:
  postgres-data:
  elasticsearch-data:
  grafana-data:
  prometheus-data:
